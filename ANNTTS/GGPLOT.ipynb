{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 35]\n",
      " [ 7 51]]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Invalid column: 'False_Positive_Rate'\ndid you mean one of the following:\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/carlsaptarshi/anaconda/lib/python3.6/site-packages/ggplot/aes.py\u001b[0m in \u001b[0;36m_evaluate_expressions\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                     \u001b[0mnew_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_namespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlsaptarshi/anaconda/lib/python3.6/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[1;32m    165\u001b[0m         return eval(code, {}, VarLookupDict([inner_namespace]\n\u001b[0;32m--> 166\u001b[0;31m                                             + self._namespaces))\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'False_Positive_Rate' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f2ace161b413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mmake_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mconfiguration_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_config_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset2.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_n_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-f2ace161b413>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(data_set, config_file, run_n_times)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mggplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'False_Positive_Rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'True_Positive_Rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mgeom_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgeom_abline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinetype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mgeom_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m         \u001b[0mggtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROC Curve w/ AUC=%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlsaptarshi/anaconda/lib/python3.6/site-packages/ggplot/ggplot.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, aesthetics, data)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_expressions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_identity_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlsaptarshi/anaconda/lib/python3.6/site-packages/ggplot/aes.py\u001b[0m in \u001b[0;36m_evaluate_expressions\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"    - %s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Invalid column: 'False_Positive_Rate'\ndid you mean one of the following:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import timeit\n",
    "import sys\n",
    "import configparser\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from ggplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_config():\n",
    "    \"\"\"\n",
    "    If a configuration file does not exist, then create a default one with default parameters.\n",
    "    :return: the configuration file\n",
    "    \"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config['DEFAULT'] = {\n",
    "        'test_size': '0.2',\n",
    "        'train_size': '0.2',\n",
    "        'structure': '5 5',\n",
    "        'activation': 'logistic',\n",
    "        'learning_method': 'lbfgs',\n",
    "        'max_iterations': '1000'\n",
    "    }\n",
    "    with open('config.ini', 'w') as configfile:\n",
    "        config.write(configfile)\n",
    "\n",
    "\n",
    "def read_config_file(file):\n",
    "    \"\"\"\n",
    "    function to read the configuration file which takes the parameters and is used to train and test the ANN.\n",
    "    :param file: the configuration file\n",
    "    :return: the configuration parameters.\n",
    "    \"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(file)\n",
    "    params = list()\n",
    "    # get the key values for each parameter\n",
    "    train_size = config['DEFAULT']['train_size']\n",
    "    test_size = config['DEFAULT']['test_size']\n",
    "    ANN_structure = config['DEFAULT']['structure']\n",
    "    learning_method = config['DEFAULT']['learning_method']\n",
    "    activation = config['DEFAULT'][\"activation\"]\n",
    "    max_iter = config['DEFAULT'][\"max_iterations\"]\n",
    "    params.append(train_size)\n",
    "    params.append(test_size)\n",
    "    params.append(ANN_structure)\n",
    "    params.append(activation)\n",
    "    params.append(learning_method)\n",
    "    params.append(max_iter)\n",
    "    return params\n",
    "\n",
    "\n",
    "def read_data(file_name):\n",
    "    \"\"\"\n",
    "    Function to read in the data file used for classification\n",
    "    :param file_name: the file to be read in for the ANN model\n",
    "    :return: the shuffled data set and its associated classification labels.\n",
    "    \"\"\"\n",
    "    # load data from file\n",
    "    CBD = np.loadtxt(file_name)\n",
    "    CBD = CBD  # to keep data consistent\n",
    "    shuffle(CBD)\n",
    "\n",
    "    class_labels_CBD = CBD[:, -1]\n",
    "    class_labels_CBD = [int(x) for x in class_labels_CBD]\n",
    "    class_labels_CBD = np.asarray(class_labels_CBD)\n",
    "\n",
    "    data_CBD = CBD[:, 0:-1]\n",
    "    return data_CBD, class_labels_CBD\n",
    "\n",
    "\n",
    "def split_data(data, labels, train_s, test_s):\n",
    "    \"\"\"\n",
    "    Function to randomly split the data into a training and testing dataset. X_train and y_train represent the\n",
    "    data used to train the model. X_test and y_test represent the data used to test the predictive accuracy of the\n",
    "    model. Here, X represents each row of data, and y represents the classification label associated with a row of data.\n",
    "    :param data: the data set without the classification labels\n",
    "    :param labels:  the classification label array\n",
    "    :param train_s: the percentage of data used to train the model\n",
    "    :param test_s: the percentage of data used to test the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, train_size=train_s, test_size=test_s)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def run_classifier(x_train, y_train, struct, x_test, activate='logistic', solve='lbfgs', iter_limit=1000):\n",
    "    \"\"\"\n",
    "    Function to train and test the ANN classifier model once using the training and testing data.\n",
    "    :param x_train: the training data\n",
    "    :param y_train: the training data classification labels\n",
    "    :param struct: the structure of the ANN, given by the config.txt file\n",
    "    :param x_test: the data to be used to test the predictive accuracy of the model\n",
    "    :param activate: the type of activation function used to transfer data from one node to the next\n",
    "    :param solve: The type of back propagation algorithm used.\n",
    "    :param iter_limit: the maximum iteration limit given to the model given by the user\n",
    "    :return: the predictions after training and testing the model\n",
    "    \"\"\"\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=struct, activation=activate, solver=solve, max_iter=iter_limit)\n",
    "    mlp.fit(x_train, y_train)\n",
    "\n",
    "    predsTESTING = mlp.predict_proba(x_test)[:,1]\n",
    "    \n",
    "    predictions = mlp.predict(x_test)\n",
    "\n",
    "    return predictions, predsTESTING\n",
    "\n",
    "\n",
    "def predictive_accuracy(predictions, y_test):\n",
    "    \"\"\"\n",
    "    Function to return the predictive accuracy of the model after testing on the hold out sample data.\n",
    "    :param predictions: the predictions from testing\n",
    "    :param y_test: the actual testing classification labels\n",
    "    :return: the percentage accuracy of the ANN model\n",
    "    \"\"\"\n",
    "    trufa = y_test == predictions\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    accuracy = round((sum(trufa) / len(trufa)) * 100)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def run(data_set, config_file, run_n_times=1):\n",
    "    \"\"\"\n",
    "    Function to run the ANN model to train and test the model.\n",
    "    :param data_set: the data set to be used to train and test the model\n",
    "    :param config_file: the configuration file to determine the ANN structure\n",
    "    :param run_n_times: the number of times to run the model\n",
    "    :return: the accuracy of the trained model on the testing data set in a out.txt file.\n",
    "    \"\"\"\n",
    "    read_d = read_data(data_set)\n",
    "    train_size = float(config_file[0])\n",
    "    test_size = float(config_file[1])\n",
    "    hidden_layers = tuple(map(int, config_file[2].split(' ')))\n",
    "    activation = config_file[3]\n",
    "    data = read_d[0]\n",
    "    labels = read_d[1]\n",
    "\n",
    "    accuracies = list()\n",
    "    times = list()\n",
    "    for i in range(run_n_times):\n",
    "        start_time = timeit.default_timer()\n",
    "        x = split_data(data, labels, train_size, test_size)\n",
    "        x_train = x[0]\n",
    "        y_train = x[1]\n",
    "        x_test = x[2]\n",
    "        y_test = x[3]\n",
    "\n",
    "        train_model = run_classifier(x_train, y_train, hidden_layers, x_test, activate=activation)\n",
    "        predsTESTING = train_model[1]\n",
    "        # print(train_model)\n",
    "        elapse = timeit.default_timer() - start_time\n",
    "        times.append(elapse)\n",
    "        predictive_accuracy(train_model[0], y_test)\n",
    "        # print(\"predictive accuracy of model: \", accuracy)\n",
    "#         accuracies.append(accuracy)\n",
    "#         print(predsTESTING)\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_test, predsTESTING)\n",
    "        df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        g = ggplot(df, aes(x='False_Positive_Rate', y='True_Positive_Rate')) +geom_line() + geom_abline(linetype='dashed')+ geom_area(alpha=0.2)+\\\n",
    "         ggtitle(\"ROC Curve w/ AUC=%s\" % str(auc))\n",
    "        g.show()\n",
    "\n",
    "#         if i % 100 == 0:\n",
    "#             # print(\"iteration: \", i)\n",
    "#             sys.stdout.write(\"iteration: \" + str(i) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    # print(accuracies)\n",
    "    # print(\"time taken\")\n",
    "    # print(times)\n",
    "\n",
    "    # plt.boxplot(accuracies)\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.plot(list(range(len(times))), times, label = \"Time taken to learn\")\n",
    "    # plt.legend(loc = \"best\")\n",
    "    # plt.show()\n",
    "    # plt.plot(list(range(len(accuracies))), accuracies, \"b\", label= \"predictive accuracies over 2000 iterations\")\n",
    "    # plt.legend(loc= \"best\")\n",
    "    \n",
    "#     save_file = open(\"./out.txt\", 'a')\n",
    "#     for i in accuracies:\n",
    "#         save_file.write(str(i))\n",
    "#         save_file.write(\", \")\n",
    "\n",
    "#     save_file.write(\"\\n\")\n",
    "#     save_file.close()\n",
    "#     sys.stdout.write(\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = './config.ini'\n",
    "    if os.path.exists(file_path):\n",
    "        # print(\"Trueeeee\")\n",
    "        configuration_file = read_config_file(file_path)\n",
    "        # print(configuration_file)\n",
    "\n",
    "    else:\n",
    "        print(\"No config file detected, creating default config.ini file\")\n",
    "        make_config()\n",
    "        configuration_file = read_config_file(file_path)\n",
    "    run('./dataset2.txt', configuration_file, run_n_times=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
